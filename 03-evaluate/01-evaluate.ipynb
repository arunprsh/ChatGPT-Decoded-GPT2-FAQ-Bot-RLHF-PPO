{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5526918-ccb7-4d6b-ad10-5de223275dd4",
   "metadata": {},
   "source": [
    "## Evaluate candidate models with BERTScore for contextual similarity to ground truth answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84fc6a5-46ce-4d37-a85e-ac0659d3e678",
   "metadata": {},
   "source": [
    "##### Prerequisite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390262a9-da5a-4d39-bb1a-b2ed099882b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install transformers==4.18.0\n",
    "!pip install pandas==1.4.1\n",
    "!pip install numpy==1.22.2\n",
    "!pip install torch==1.8.1\n",
    "!pip install evaluate==0.4.0\n",
    "!pip install bert-score==0.3.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fb976-c94b-4a58-a545-03a80b42fc88",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874b6784-66e6-4206-952e-c6b7685944c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from transformers import set_seed\n",
    "from evaluate import load\n",
    "import transformers \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bert_score\n",
    "import evaluate\n",
    "import logging\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69545a48-b529-4e2f-92b9-399ad314f539",
   "metadata": {},
   "source": [
    "##### Setup logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e8036b-d35a-4f3b-9c4c-e2e3cb313f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06e7ac-ac80-46cc-9a99-f2d3a8828593",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0381b965-0fa8-4575-9a6f-4890d11500a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using transformers version: 4.18.0]\n",
      "[Using bert_score version: 0.3.12]\n",
      "[Using evaluate version: 0.4.0]\n",
      "[Using torch version: 1.8.1+cu102]\n",
      "[Using pandas version: 1.4.1]\n",
      "[Using numpy version: 1.22.2]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using transformers version: {transformers.__version__}]')\n",
    "logger.info(f'[Using bert_score version: {bert_score.__version__}]')\n",
    "logger.info(f'[Using evaluate version: {evaluate.__version__}]')\n",
    "logger.info(f'[Using torch version: {torch.__version__}]')\n",
    "logger.info(f'[Using pandas version: {pd.__version__}]')\n",
    "logger.info(f'[Using numpy version: {np.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc505f-3f9c-45bc-87d6-ca9ae2ebcc8b",
   "metadata": {},
   "source": [
    "#### Setup essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6c18e1-fed8-4e64-89b8-0720e7bed7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(123)\n",
    "np.random.seed(123)\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c34f35-6c09-4b35-9175-30648c023db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOS_TOKEN = '<|startoftext|>'\n",
    "EOS_TOKEN = '<|endoftext|>'\n",
    "PAD_TOKEN = '<|pad|>'\n",
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9d2dd4-cb21-42ef-9019-1c1ea3dadfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bertscore = load('bertscore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a41c6e-7e75-47c4-a95d-9aee7b5f84bc",
   "metadata": {},
   "source": [
    "#### Load custom tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004f4fe3-b555-4a92-9b81-d5bba1128907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Custom Tokenizer: PreTrainedTokenizer(name_or_path='../01-tokenize/vocab-custom', vocab_size=50257, model_max_len=512, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})\n"
     ]
    }
   ],
   "source": [
    "custom_tokenizer = GPT2Tokenizer.from_pretrained('../01-tokenize/vocab-custom', \n",
    "                                                 bos_token=BOS_TOKEN, \n",
    "                                                 eos_token=EOS_TOKEN, \n",
    "                                                 pad_token=PAD_TOKEN, \n",
    "                                                 lower=True,\n",
    "                                                 return_tensors='pt')\n",
    "custom_tokenizer.padding_side = 'left'\n",
    "custom_tokenizer.model_max_length = MAX_LEN\n",
    "logger.info(f'Custom Tokenizer: {custom_tokenizer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7259f29d-2e4f-4aca-8fd6-e1b07e9ef019",
   "metadata": {},
   "source": [
    "#### Load OOB tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aa90d68-4cc2-4fb8-935a-5fc537a3a396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "OOB Tokenizer: PreTrainedTokenizer(name_or_path='gpt2', vocab_size=50257, model_max_len=512, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})\n"
     ]
    }
   ],
   "source": [
    "oob_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
    "                                              bos_token=BOS_TOKEN, \n",
    "                                              eos_token=EOS_TOKEN, \n",
    "                                              pad_token=PAD_TOKEN, \n",
    "                                              lower=True,\n",
    "                                              return_tensors='pt')\n",
    "oob_tokenizer.padding_side = 'left'\n",
    "oob_tokenizer.model_max_length = MAX_LEN\n",
    "logger.info(f'OOB Tokenizer: {oob_tokenizer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3bdcc-20a7-4a9e-8e1e-b7ea0cfdd828",
   "metadata": {},
   "source": [
    "#### Load custom GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04e90f7-039e-49ca-8b64-e6c758c2c0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model = transformers.AutoModelForCausalLM.from_pretrained('.././02-finetune/model/custom-finetuned')\n",
    "_ = custom_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64d6db7-7d18-47ef-a6b0-7dd863d2c45c",
   "metadata": {},
   "source": [
    "#### Load OOB GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "444feb6b-9365-4da2-a4f0-2c2ed9877aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oob_model = transformers.AutoModelForCausalLM.from_pretrained('.././02-finetune/model/oob-finetuned')\n",
    "_ = oob_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47cd54-126b-47ff-9ff7-0603e7cf2a92",
   "metadata": {},
   "source": [
    "#### Load test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e2eb4f0-3220-4065-bf3d-93ec3d1e3a47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    681\n",
       "answer      681\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('.././01-tokenize/data/faq_test.csv')\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e056f30-a5b2-4a8e-9e37-f835a78c88ae",
   "metadata": {},
   "source": [
    "#### Collect predicted responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3652b64a-77ed-445a-ad5d-691118362c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(question: str, ground_truth: str, tokenizer: GPT2Tokenizer, model: transformers.AutoModelForCausalLM) -> str:\n",
    "    # create a prompt in compliance with the one used during training without the answer part\n",
    "    prompt = f'{BOS_TOKEN}question: {question}\\nanswer:'\n",
    "    # generate tokens\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "    # predict response (answer)\n",
    "    gt_len = len(ground_truth.split())\n",
    "    response = model.generate(input_ids, \n",
    "                              do_sample=True, \n",
    "                              top_k=1, \n",
    "                              min_new_tokens=gt_len * 2,\n",
    "                              max_new_tokens=gt_len * 2, \n",
    "                              repetition_penalty=10.0,\n",
    "                              length_penalty=-0.1,\n",
    "                              pad_token_id=tokenizer.eos_token_id,\n",
    "                              eos_token_id=-1,\n",
    "                              top_p=1.0)\n",
    "    # decode the predicted tokens into texts\n",
    "    response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "    answer = response_text.split('answer: ')[-1]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af308171-19ed-4141-b87f-2837ec95796f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_gpt2_answers = []\n",
    "oob_gpt2_answers = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    question, ground_truth = row\n",
    "    answer = predict(question, ground_truth, custom_tokenizer, custom_model)\n",
    "    custom_gpt2_answers.append(answer)\n",
    "    answer = predict(question, ground_truth, oob_tokenizer, oob_model)\n",
    "    oob_gpt2_answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f69433-3b12-4b77-ae6c-67233086b5a0",
   "metadata": {},
   "source": [
    "#### Compute BERTScore for the predictions against ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82cc54-5b84-49e3-93b6-a910caf41900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bert_score_custom_gpt2 = bertscore.compute(predictions=custom_gpt2_answers, references=test_df['answer'].to_list(), lang='en')['f1']\n",
    "bert_score_oob_gpt2 = bertscore.compute(predictions=oob_gpt2_answers, references=test_df['answer'].to_list(), lang='en')['f1']\n",
    "    \n",
    "test_df['custom_gpt2_answer'] = custom_gpt2_answers\n",
    "test_df['oob_gpt2_answer'] = oob_gpt2_answers\n",
    "\n",
    "test_df['bert_score_custom_gpt2'] = bert_score_custom_gpt2\n",
    "test_df['bert_score_oob_gpt2'] = bert_score_oob_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c977ce7-5a2d-4a7b-b445-33f2242f5b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45291c-0054-4025-b8b1-4a214ba9e355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(test_df['bert_score_custom_gpt2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fb17fe-4322-4e0a-8ef4-316f24c34c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(test_df['bert_score_oob_gpt2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a403d636-3088-4480-ad0e-a5a9dca453e9",
   "metadata": {},
   "source": [
    "#### Write evaluation results to local dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48fcca-c729-4a03-a347-290976d1e619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.to_csv('./data/eval_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d54d3-22c4-4f00-8dde-df1308e2d55b",
   "metadata": {},
   "source": [
    "#### Create classification dataset for BERT finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c06e3-844f-4fbc-ba9b-24dc0852ce80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('./data/eval_results.csv')\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ec07c-e290-4c1d-a952-97519f125723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb566a4-de83-44a3-933a-29b8f23c4e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _, row in results_df.iterrows():\n",
    "    _, _, custom_gpt2_answer, oob_gpt2_answer, bert_score_custom_gpt2, bert_score_oob_gpt2 = row\n",
    "    if bert_score_custom_gpt2 > bert_score_oob_gpt2:\n",
    "        dataset[custom_gpt2_answer] = 1\n",
    "        dataset[oob_gpt2_answer] = 0\n",
    "    elif bert_score_custom_gpt2 < bert_score_oob_gpt2:\n",
    "        dataset[custom_gpt2_answer] = 0\n",
    "        dataset[oob_gpt2_answer] = 1\n",
    "    else:  # corner case when the scores are equal \n",
    "        len_1 = len(custom_gpt2_answer)\n",
    "        len_2 = len(oob_gpt2_answer)\n",
    "        if len_1 < len_2:\n",
    "            dataset[custom_gpt2_answer] = 1\n",
    "            dataset[oob_gpt2_answer] = 0\n",
    "        elif len_1 > len_2:\n",
    "            dataset[custom_gpt2_answer] = 0\n",
    "            dataset[oob_gpt2_answer] = 1\n",
    "        else:\n",
    "            # extreme corner case when both responses are either identical or of the same length with the same BERTscores \n",
    "            dataset[custom_gpt2_answer] = 1\n",
    "            dataset[oob_gpt2_answer] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e7125-0fbb-4ddf-986c-c8901c7afdb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_dataset = pd.DataFrame(list(dataset.items()), columns=['response', 'label'])\n",
    "clf_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7bd21-b376-47f3-a222-005cb0276bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967a9f1-7c0c-4ef6-8d54-91ee5fee7e00",
   "metadata": {},
   "source": [
    "##### Write the clf dataset to local dir after shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46908c79-fb92-412e-a331-cc6a2b93db89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_dataset = clf_dataset.sample(frac=1).reset_index(drop=True)\n",
    "clf_dataset.to_csv('./data/clf_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8a136-e7d1-4414-bd0e-e22e7edefd56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
