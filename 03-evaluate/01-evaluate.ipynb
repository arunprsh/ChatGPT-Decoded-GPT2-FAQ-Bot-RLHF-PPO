{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5526918-ccb7-4d6b-ad10-5de223275dd4",
   "metadata": {},
   "source": [
    "## Evaluate candidate models with BERTScore for contextual similarity to ground truth answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84fc6a5-46ce-4d37-a85e-ac0659d3e678",
   "metadata": {},
   "source": [
    "##### Prerequisite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390262a9-da5a-4d39-bb1a-b2ed099882b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install transformers==4.18.0\n",
    "!pip install pandas==1.4.1\n",
    "!pip install numpy==1.22.2\n",
    "!pip install torch==1.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fb976-c94b-4a58-a545-03a80b42fc88",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "874b6784-66e6-4206-952e-c6b7685944c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from transformers import set_seed\n",
    "import transformers \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69545a48-b529-4e2f-92b9-399ad314f539",
   "metadata": {},
   "source": [
    "##### Setup logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e8036b-d35a-4f3b-9c4c-e2e3cb313f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06e7ac-ac80-46cc-9a99-f2d3a8828593",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0381b965-0fa8-4575-9a6f-4890d11500a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using transformers version: 4.18.0]\n",
      "[Using torch version: 1.8.1+cu102]\n",
      "[Using pandas version: 1.4.1]\n",
      "[Using numpy version: 1.22.2]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using transformers version: {transformers.__version__}]')\n",
    "logger.info(f'[Using torch version: {torch.__version__}]')\n",
    "logger.info(f'[Using pandas version: {pd.__version__}]')\n",
    "logger.info(f'[Using numpy version: {np.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc505f-3f9c-45bc-87d6-ca9ae2ebcc8b",
   "metadata": {},
   "source": [
    "#### Setup essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6c18e1-fed8-4e64-89b8-0720e7bed7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c34f35-6c09-4b35-9175-30648c023db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOS_TOKEN = '<|startoftext|>'\n",
    "EOS_TOKEN = '<|endoftext|>'\n",
    "PAD_TOKEN = '<|pad|>'\n",
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a41c6e-7e75-47c4-a95d-9aee7b5f84bc",
   "metadata": {},
   "source": [
    "#### Load custom tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004f4fe3-b555-4a92-9b81-d5bba1128907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Custom Tokenizer: PreTrainedTokenizer(name_or_path='../01-tokenize/vocab-custom', vocab_size=50257, model_max_len=512, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})\n"
     ]
    }
   ],
   "source": [
    "custom_tokenizer = GPT2Tokenizer.from_pretrained('../01-tokenize/vocab-custom', \n",
    "                                                 bos_token=BOS_TOKEN, \n",
    "                                                 eos_token=EOS_TOKEN, \n",
    "                                                 pad_token=PAD_TOKEN, \n",
    "                                                 return_tensors='pt')\n",
    "custom_tokenizer.padding_side = 'left'\n",
    "custom_tokenizer.model_max_length = MAX_LEN\n",
    "logger.info(f'Custom Tokenizer: {custom_tokenizer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7259f29d-2e4f-4aca-8fd6-e1b07e9ef019",
   "metadata": {},
   "source": [
    "#### Load OOB tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aa90d68-4cc2-4fb8-935a-5fc537a3a396",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "OOB Tokenizer: PreTrainedTokenizer(name_or_path='gpt2', vocab_size=50257, model_max_len=512, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})\n"
     ]
    }
   ],
   "source": [
    "oob_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
    "                                              bos_token=BOS_TOKEN, \n",
    "                                              eos_token=EOS_TOKEN, \n",
    "                                              pad_token=PAD_TOKEN, \n",
    "                                              return_tensors='pt')\n",
    "oob_tokenizer.padding_side = 'left'\n",
    "oob_tokenizer.model_max_length = MAX_LEN\n",
    "logger.info(f'OOB Tokenizer: {oob_tokenizer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3bdcc-20a7-4a9e-8e1e-b7ea0cfdd828",
   "metadata": {},
   "source": [
    "#### Load custom GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b04e90f7-039e-49ca-8b64-e6c758c2c0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model = transformers.AutoModelForCausalLM.from_pretrained('.././02-finetune/model/custom-finetuned')\n",
    "_ = custom_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64d6db7-7d18-47ef-a6b0-7dd863d2c45c",
   "metadata": {},
   "source": [
    "#### Load OOB GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444feb6b-9365-4da2-a4f0-2c2ed9877aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oob_model = transformers.AutoModelForCausalLM.from_pretrained('.././02-finetune/model/oob-finetuned')\n",
    "_ = oob_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47cd54-126b-47ff-9ff7-0603e7cf2a92",
   "metadata": {},
   "source": [
    "#### Load test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e2eb4f0-3220-4065-bf3d-93ec3d1e3a47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have a few symptoms like the stomachache, co...</td>\n",
       "      <td>stomach troubles aren't a common symptom of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social distancing &amp; business operations during...</td>\n",
       "      <td>q. do you have best practices to share with re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>should i wear a respirator in public?</td>\n",
       "      <td>most often, spread of respiratory viruses from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>set boundaries so caring for the person doesn’...</td>\n",
       "      <td>it’s very important to continue taking care of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what if my time off is not approved and i don’...</td>\n",
       "      <td>you will be treated just as you would if you d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>visit your local election website for vote by ...</td>\n",
       "      <td>in most states, you’ll need to apply by a cert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>i have developed a serology test kit for sars-...</td>\n",
       "      <td>all clinical tests should be validated prior t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>will vodka or other hard alcohols work as disi...</td>\n",
       "      <td>vodka, or other hard alcohols, are not recomme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>try to avoid talking about the virus all the t...</td>\n",
       "      <td>while the virus is probably on everyone’s mind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>schedule each day so you can stick to a routine.</td>\n",
       "      <td>plan out your day as though you were still sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    i have a few symptoms like the stomachache, co...   \n",
       "1    social distancing & business operations during...   \n",
       "2                should i wear a respirator in public?   \n",
       "3    set boundaries so caring for the person doesn’...   \n",
       "4    what if my time off is not approved and i don’...   \n",
       "..                                                 ...   \n",
       "353  visit your local election website for vote by ...   \n",
       "354  i have developed a serology test kit for sars-...   \n",
       "355  will vodka or other hard alcohols work as disi...   \n",
       "356  try to avoid talking about the virus all the t...   \n",
       "357   schedule each day so you can stick to a routine.   \n",
       "\n",
       "                                                answer  \n",
       "0    stomach troubles aren't a common symptom of th...  \n",
       "1    q. do you have best practices to share with re...  \n",
       "2    most often, spread of respiratory viruses from...  \n",
       "3    it’s very important to continue taking care of...  \n",
       "4    you will be treated just as you would if you d...  \n",
       "..                                                 ...  \n",
       "353  in most states, you’ll need to apply by a cert...  \n",
       "354  all clinical tests should be validated prior t...  \n",
       "355  vodka, or other hard alcohols, are not recomme...  \n",
       "356  while the virus is probably on everyone’s mind...  \n",
       "357  plan out your day as though you were still sta...  \n",
       "\n",
       "[358 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('.././01-tokenize/data/faq_test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e056f30-a5b2-4a8e-9e37-f835a78c88ae",
   "metadata": {},
   "source": [
    "#### Collect predicted responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af308171-19ed-4141-b87f-2837ec95796f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have a few symptoms like the stomachache, congestion, and diarrhea but no fever. is it possible i have the virus?\n",
      "question: i have a few symptoms like the stomachache, congestion, and diarrhea but no fever. is it possible i have the virus?\n",
      "answer: the virus that causes covid-19 is thought to spread mainly from person-to-person through respiratory droplets produced when an infected person coughs, sneezes, or talks. this is why it is so important to practice social distancing.\n",
      "\n",
      "if you have symptoms of covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your symptoms.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor your health.\n",
      "if you have been around someone who has covid-19, you should stay home and monitor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _, row in test_df.iterrows():\n",
    "    question, ground_truth = row\n",
    "    print(question)\n",
    "    # create a prompt in compliance with the one used during training without the answer part\n",
    "    prompt = f'{BOS_TOKEN}question: {question}\\nanswer:'\n",
    "    # generate tokens\n",
    "    input_ids = custom_tokenizer(prompt, return_tensors='pt').input_ids\n",
    "    # predict response (answer)\n",
    "    response = custom_model.generate(input_ids, \n",
    "                                     do_sample=True, \n",
    "                                     top_k=50, \n",
    "                                     max_length=512, \n",
    "                                     top_p=0.90, \n",
    "                                     temperature=0.2)\n",
    "    # decode the predicted tokens into texts\n",
    "    answer = custom_tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "    print(answer)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c977ce7-5a2d-4a7b-b445-33f2242f5b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482fd12-b5fb-4540-b1a1-6ced51a141a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab540a-34d1-4650-ad3b-7ab68f615874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddeff9-af17-43b5-a03b-e4c342bc84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for text, label in zip(X_test, y_test):\n",
    "    text = text[0:256]\n",
    "    # create prompt (in compliance with the one used during training)\n",
    "    prompt = f'<|startoftext|>question: {text}\\nanswer:'\n",
    "    \n",
    "    \n",
    "    # generate tokens\n",
    "    generated = tokenizer(f\"{prompt}\", return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # perform prediction\n",
    "    sample_outputs = model.generate(generated, \n",
    "                                    do_sample=True, \n",
    "                                    top_k=50, \n",
    "                                    max_length=256, \n",
    "                                    top_p=0.90, \n",
    "                                    temperature=0.2)\n",
    "\n",
    "\n",
    "    # decode the predicted tokens into texts\n",
    "    pred_text  = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "    print(pred_text)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
