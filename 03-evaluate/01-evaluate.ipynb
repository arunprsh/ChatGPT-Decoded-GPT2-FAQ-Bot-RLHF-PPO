{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5526918-ccb7-4d6b-ad10-5de223275dd4",
   "metadata": {},
   "source": [
    "## Evaluate candidate models with BERTScore for contextual similarity to ground truth answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84fc6a5-46ce-4d37-a85e-ac0659d3e678",
   "metadata": {},
   "source": [
    "##### Prerequisite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390262a9-da5a-4d39-bb1a-b2ed099882b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install transformers==4.18.0\n",
    "!pip install pandas==1.4.1\n",
    "!pip install numpy==1.22.2\n",
    "!pip install torch==1.8.1\n",
    "!pip install evaluate\n",
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fb976-c94b-4a58-a545-03a80b42fc88",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874b6784-66e6-4206-952e-c6b7685944c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from transformers import set_seed\n",
    "from evaluate import load\n",
    "import transformers \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69545a48-b529-4e2f-92b9-399ad314f539",
   "metadata": {},
   "source": [
    "##### Setup logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e8036b-d35a-4f3b-9c4c-e2e3cb313f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06e7ac-ac80-46cc-9a99-f2d3a8828593",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0381b965-0fa8-4575-9a6f-4890d11500a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using transformers version: 4.18.0]\n",
      "[Using torch version: 1.8.1+cu102]\n",
      "[Using pandas version: 1.4.1]\n",
      "[Using numpy version: 1.22.2]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using transformers version: {transformers.__version__}]')\n",
    "logger.info(f'[Using torch version: {torch.__version__}]')\n",
    "logger.info(f'[Using pandas version: {pd.__version__}]')\n",
    "logger.info(f'[Using numpy version: {np.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc505f-3f9c-45bc-87d6-ca9ae2ebcc8b",
   "metadata": {},
   "source": [
    "#### Setup essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6c18e1-fed8-4e64-89b8-0720e7bed7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c34f35-6c09-4b35-9175-30648c023db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOS_TOKEN = '<|startoftext|>'\n",
    "EOS_TOKEN = '<|endoftext|>'\n",
    "PAD_TOKEN = '<|pad|>'\n",
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9d2dd4-cb21-42ef-9019-1c1ea3dadfa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bertscore = load('bertscore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a41c6e-7e75-47c4-a95d-9aee7b5f84bc",
   "metadata": {},
   "source": [
    "#### Load custom tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004f4fe3-b555-4a92-9b81-d5bba1128907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Custom Tokenizer: PreTrainedTokenizer(name_or_path='../01-tokenize/vocab-custom', vocab_size=50257, model_max_len=512, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})\n"
     ]
    }
   ],
   "source": [
    "custom_tokenizer = GPT2Tokenizer.from_pretrained('../01-tokenize/vocab-custom', \n",
    "                                                 bos_token=BOS_TOKEN, \n",
    "                                                 eos_token=EOS_TOKEN, \n",
    "                                                 pad_token=PAD_TOKEN, \n",
    "                                                 lower=True,\n",
    "                                                 return_tensors='pt')\n",
    "custom_tokenizer.padding_side = 'left'\n",
    "custom_tokenizer.model_max_length = MAX_LEN\n",
    "logger.info(f'Custom Tokenizer: {custom_tokenizer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7259f29d-2e4f-4aca-8fd6-e1b07e9ef019",
   "metadata": {},
   "source": [
    "#### Load OOB tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa90d68-4cc2-4fb8-935a-5fc537a3a396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oob_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
    "                                              bos_token=BOS_TOKEN, \n",
    "                                              eos_token=EOS_TOKEN, \n",
    "                                              pad_token=PAD_TOKEN, \n",
    "                                              lower=True,\n",
    "                                              return_tensors='pt')\n",
    "oob_tokenizer.padding_side = 'left'\n",
    "oob_tokenizer.model_max_length = MAX_LEN\n",
    "logger.info(f'OOB Tokenizer: {oob_tokenizer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3bdcc-20a7-4a9e-8e1e-b7ea0cfdd828",
   "metadata": {},
   "source": [
    "#### Load custom GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e90f7-039e-49ca-8b64-e6c758c2c0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model = transformers.AutoModelForCausalLM.from_pretrained('.././02-finetune/model/custom-finetuned')\n",
    "_ = custom_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64d6db7-7d18-47ef-a6b0-7dd863d2c45c",
   "metadata": {},
   "source": [
    "#### Load OOB GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444feb6b-9365-4da2-a4f0-2c2ed9877aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oob_model = transformers.AutoModelForCausalLM.from_pretrained('.././02-finetune/model/oob-finetuned')\n",
    "_ = oob_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47cd54-126b-47ff-9ff7-0603e7cf2a92",
   "metadata": {},
   "source": [
    "#### Load test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2eb4f0-3220-4065-bf3d-93ec3d1e3a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('.././01-tokenize/data/faq_test.csv')\n",
    "test_df = test_df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e056f30-a5b2-4a8e-9e37-f835a78c88ae",
   "metadata": {},
   "source": [
    "#### Collect predicted responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652b64a-77ed-445a-ad5d-691118362c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(question: str, ground_truth: str, tokenizer: GPT2Tokenizer, model: transformers.AutoModelForCausalLM) -> str:\n",
    "    # create a prompt in compliance with the one used during training without the answer part\n",
    "    prompt = f'{BOS_TOKEN}question: {question}\\nanswer:'\n",
    "    # generate tokens\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "    # predict response (answer)\n",
    "    response = model.generate(input_ids, \n",
    "                              do_sample=True, \n",
    "                              top_k=1, \n",
    "                              max_length=MAX_LEN, \n",
    "                              repetition_penalty=10.0,\n",
    "                              top_p=1.0)\n",
    "    # decode the predicted tokens into texts\n",
    "    response_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "    answer = response_text.split('answer: ')[-1]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af308171-19ed-4141-b87f-2837ec95796f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_gpt2_answers = []\n",
    "oob_gpt2_answers = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    question, ground_truth = row\n",
    "    custom_gpt2_answers.append(predict(question, ground_truth, custom_tokenizer, custom_model))\n",
    "    oob_gpt2_answers.append(predict(question, ground_truth, oob_tokenizer, oob_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82cc54-5b84-49e3-93b6-a910caf41900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cresults = bertscore.compute(predictions=custom_gpt2_answers, references=test_df['answer'].to_list(), lang=\"en\")['f1']\n",
    "oresults = bertscore.compute(predictions=oob_gpt2_answers, references=test_df['answer'].to_list(), lang=\"en\")['f1']\n",
    "    \n",
    "test_df['custom_gpt2_answer'] = custom_gpt2_answers\n",
    "test_df['oob_gpt2_answer'] = oob_gpt2_answers\n",
    "\n",
    "test_df['cresults'] = cresults\n",
    "test_df['oresults'] = oresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05130839-d190-4c9e-9ae7-1a85902de95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_gpt2_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c977ce7-5a2d-4a7b-b445-33f2242f5b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4053b94-d43e-44e9-aff9-1c52c23df3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _, row in test_df.iterrows():\n",
    "    q, a, c_ans, o_ans, _, _ = row\n",
    "    print('Q: ', q)\n",
    "    print()\n",
    "    print('A: ', a)\n",
    "    print()\n",
    "    print('CA: ', c_ans)\n",
    "    print()\n",
    "    print('OA: ', o_ans)\n",
    "    print()\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b5b75-6b1a-4028-89ee-a31425656388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48fcca-c729-4a03-a347-290976d1e619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac925a30-6443-49fe-bc65-ca1317ee1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5035b8-6dad-4371-a45d-b89dbb3fc5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(df['cresults'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cbc23-34f6-4017-8712-0ff2782758fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(df['oresults'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d630b-aac3-490a-af57-46d93608de07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b949cb36-1ec8-4f28-992a-485260908d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5033296c-2cad-45ba-8b97-beb5a6e6fef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b371f84-1704-45f7-88fd-48d4218778de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7c4d6-cb1a-4bd9-9ff5-62526f90e659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be216d55-96fb-4a49-a5fe-af56146b22c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388eb13-58e8-461e-aa9e-d4068589f627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8432af-550c-4a40-90db-a0a7153b73b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3260e-9b23-4cbc-a9f4-7495d777aad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314d869-fc62-4727-ad7c-2780ece62725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "qs = []\n",
    "anss = []\n",
    "ccans = []\n",
    "ooans = []\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    ques, ans, cans, oans, _, _ = row\n",
    "    ans = ans.replace('\\n', ' ')\n",
    "    ans = ans.replace('  ', ' ')\n",
    "    ans = ans.split('. ')\n",
    "  \n",
    "    if len(ans) <= 3:\n",
    "        print(ans)\n",
    "        max_len = len('. '.join(ans).strip())\n",
    "        print(max_len)\n",
    "        print()\n",
    "        print(cans[:max_len])\n",
    "        print()\n",
    "        print(oans[:max_len])\n",
    "        print('-' * 200)\n",
    "        i += 1\n",
    "        qs.append(ques)\n",
    "        anss.append(ans)\n",
    "        ccans.append(cans[:max_len])\n",
    "        ooans.append(oans[:max_len])\n",
    "\n",
    "\n",
    "    \n",
    "ccresults = bertscore.compute(predictions=custom_gpt2_answers, \n",
    "                              references=test_df['answer'].to_list(), lang=\"en\")['f1']\n",
    "oresults = bertscore.compute(predictions=oob_gpt2_answers, references=test_df['answer'].to_list(), lang=\"en\")['f1']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943e0ba-d917-4875-9a7f-d8f7813adfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5b516-dcc7-4246-921a-fb8f5b085e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215b5893-0b44-44fc-aaa9-d3e62b41de8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
