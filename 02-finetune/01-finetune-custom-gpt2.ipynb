{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d2f4db-014f-4fd0-895d-97a77b05651c",
   "metadata": {},
   "source": [
    "## Finetune custom GPT2 for Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe2d62-aaba-4ad4-a97e-c6057ada8d43",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7f771-c229-4d06-a184-61086c2f6e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install --upgrade jupyter\n",
    "!pip install --upgrade ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5114e05-6bc6-44dd-b635-7c0a4b960650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install transformers==4.18.0\n",
    "!pip install datasets==2.9.0\n",
    "!pip install pandas==1.4.1\n",
    "!pip install numpy==1.22.2\n",
    "!pip install wandb==0.13.9\n",
    "!pip install torch==1.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4821d30c-2676-4440-b00f-fe292eed9070",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b148e229-3459-4f37-8174-4aed38af8685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import GPT2LMHeadModel\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import Trainer\n",
    "import transformers \n",
    "import numpy as np\n",
    "import datasets\n",
    "import logging\n",
    "import torch\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a33d6-83e9-40b5-a61d-e6f7869028c9",
   "metadata": {},
   "source": [
    "##### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5875531-bb9d-4aee-9ade-e5d0a2c394d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c825d3-09e0-4b49-b644-d283f42019b8",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825f8943-e454-447f-a374-b8d72dc26102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using transformers version: 4.18.0]\n",
      "[Using datasets version: 2.9.0]\n",
      "[Using torch version: 1.8.1+cu102]\n",
      "[Using wandb version: 0.13.9]\n",
      "[Using numpy version: 1.22.2]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using transformers version: {transformers.__version__}]')\n",
    "logger.info(f'[Using datasets version: {datasets.__version__}]')\n",
    "logger.info(f'[Using torch version: {torch.__version__}]')\n",
    "logger.info(f'[Using wandb version: {wandb.__version__}]')\n",
    "logger.info(f'[Using numpy version: {np.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98b39c-331b-478e-9794-a4210f19cbd6",
   "metadata": {},
   "source": [
    "##### Setup essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93451546-6fa0-4b90-aa5e-254ef117d24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_EPOCHS = 2\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "EVAL_BATCH_SIZE = 4\n",
    "MAX_LEN = 512\n",
    "LOGGING_STEPS = 64\n",
    "SAVE_STEPS = 10240  # reduce it to a smaler value like 512 if you want to save checkpoints\n",
    "SAVE_TOTAL_LIMIT = 2\n",
    "\n",
    "BOS_TOKEN = '<|startoftext|>'\n",
    "EOS_TOKEN = '<|endoftext|>'\n",
    "PAD_TOKEN = '<|pad|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9779be0f-cb0f-43ac-93d2-cc9afd9e79b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login <USE YOUR WEIGHTS & BIASES API KEY HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fcd9da-5462-4291-9451-a7533d63fda5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/how-to-train-faq-chatbot-from-scratch/02-finetune/01-finetune-custom-gpt2.ipynb'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.abspath('01-finetune-custom-gpt2.ipynb')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0f5b7f-bc68-4150-b01e-72b5394cbef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024bed2-4c4c-4674-836f-601c9f4348c5",
   "metadata": {},
   "source": [
    "#### Load tokenized dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35bf10e8-ade5-429e-b644-25ee4e14eeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1428\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 159\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_dataset = datasets.load_from_disk('.././01-tokenize/data/tokenized-custom')\n",
    "reloaded_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd3390-7481-4e1f-bcb3-d8f23c0c2e37",
   "metadata": {},
   "source": [
    "#### Re-load custom tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5269f0fb-ab56-412f-aad0-b6f8cdab4c07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Tokenizer: PreTrainedTokenizer(name_or_path='.././01-tokenize/vocab-custom', vocab_size=50257, model_max_len=512, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('.././01-tokenize/vocab-custom', \n",
    "                                          bos_token=BOS_TOKEN,\n",
    "                                          eos_token=EOS_TOKEN, \n",
    "                                          pad_token=PAD_TOKEN, \n",
    "                                          lower=True,\n",
    "                                          return_tensors='pt')\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.model_max_length = MAX_LEN\n",
    "logger.info(f'Tokenizer: {tokenizer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a360e9-9060-49b5-91ae-55ccee9d924b",
   "metadata": {},
   "source": [
    "#### Re-load custom model from HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "784ce134-ad54-4559-b652-d6134f92c0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('arun-shankar/GPT-2-covid-news-articles').cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e2331e-c9ab-48d5-a57d-7640d210691a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_data_collator(batch):\n",
    "    # batch size for data collation = per_device_train_batch_size * number of GPUs\n",
    "    input_ids = torch.stack([example['input_ids'] for example in batch])\n",
    "    attention_mask = torch.stack([example['attention_mask'] for example in batch])\n",
    "    labels = torch.stack([example['labels'] for example in batch])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57bc6c01-1d7d-404f-b443-74ef5ebbcba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./model/custom-finetuned', \n",
    "                                  overwrite_output_dir=True, \n",
    "                                  num_train_epochs=TRAIN_EPOCHS,  \n",
    "                                  optim='adamw_torch', \n",
    "                                  save_strategy='steps', \n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  per_device_train_batch_size=TRAIN_BATCH_SIZE, \n",
    "                                  per_device_eval_batch_size=EVAL_BATCH_SIZE, \n",
    "                                  warmup_steps=10, \n",
    "                                  weight_decay=0.1,\n",
    "                                  logging_steps=LOGGING_STEPS,\n",
    "                                  save_steps=SAVE_STEPS, \n",
    "                                  save_total_limit=SAVE_TOTAL_LIMIT,\n",
    "                                  report_to='wandb',\n",
    "                                  logging_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4436dddd-ec65-46b1-8570-a7d4c558e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  train_dataset=reloaded_dataset['train'], \n",
    "                  eval_dataset=reloaded_dataset['validation'], \n",
    "                  data_collator=custom_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "585f52fc-f336-4bca-9430-079fde2a3527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1428\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 714\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshankar-arunp\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/how-to-train-faq-chatbot-from-scratch/02-finetune/wandb/run-20230207_050806-ok5fkn0l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/shankar-arunp/huggingface/runs/ok5fkn0l\" target=\"_blank\">./model/custom-finetuned</a></strong> to <a href=\"https://wandb.ai/shankar-arunp/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/shankar-arunp/huggingface\" target=\"_blank\">https://wandb.ai/shankar-arunp/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/shankar-arunp/huggingface/runs/ok5fkn0l\" target=\"_blank\">https://wandb.ai/shankar-arunp/huggingface/runs/ok5fkn0l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='714' max='714' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [714/714 07:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.411804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.322400</td>\n",
       "      <td>0.423642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 159\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 159\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=714, training_loss=0.4377530195465943, metrics={'train_runtime': 478.2739, 'train_samples_per_second': 5.971, 'train_steps_per_second': 1.493, 'total_flos': 746250043392000.0, 'train_loss': 0.4377530195465943, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34090b38-f771-4876-8472-5def79f3ebff",
   "metadata": {},
   "source": [
    "#### Save finetuned model to local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97879c57-d3e1-40a4-b1c9-5fd577b39318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./model/custom-finetuned\n",
      "Configuration saved in ./model/custom-finetuned/config.json\n",
      "Model weights saved in ./model/custom-finetuned/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./model/custom-finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93deb0-af54-4a9f-bba0-2707b1fba969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
