{
    "os": "Linux-4.14.301-224.520.amzn2.x86_64-x86_64-with-glibc2.10",
    "python": "3.8.10",
    "heartbeatAt": "2023-02-02T23:52:34.029826",
    "startedAt": "2023-02-02T23:52:33.465262",
    "docker": null,
    "cuda": null,
    "args": null,
    "state": "running",
    "program": "GPT2-CUSTOM-QA-FINETUNING",
    "git": {
        "remote": "https://github.com/arunprsh/how-to-train-faq-chatbot-from-scratch.git",
        "commit": "4200794837998a6271abbbec586802a960f17d58"
    },
    "email": "arunprsh@amazon.com",
    "root": "/root/how-to-train-faq-chatbot-from-scratch",
    "host": "pytorch-1-10-gpu--ml-g4dn-12xlarge-14fecedc15dcd66d30785ee21f10",
    "username": "root",
    "executable": "/opt/conda/bin/python",
    "cpu_count": 24,
    "cpu_count_logical": 48,
    "cpu_freq": {
        "current": 1938.2355625,
        "min": 0.0,
        "max": 0.0
    },
    "cpu_freq_per_core": [
        {
            "current": 2855.139,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1639.309,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1435.164,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1789.58,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1846.759,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1856.767,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1888.228,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1885.335,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1850.423,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1887.931,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1952.873,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1953.968,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1941.176,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2362.119,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1959.987,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1803.571,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2097.609,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1915.38,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1923.709,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1880.102,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1645.334,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2016.065,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1960.286,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1933.401,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2976.462,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1873.754,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1888.42,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1871.058,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1933.522,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1724.343,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1975.713,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1943.529,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1896.847,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1870.601,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1935.125,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1930.548,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1915.353,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2071.69,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1961.304,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2112.862,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1758.959,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1924.992,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1894.467,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1754.054,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1997.163,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1752.321,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1906.871,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1885.134,
            "min": 0.0,
            "max": 0.0
        }
    ],
    "disk": {
        "total": 27.0,
        "used": 1.7678375244140625
    },
    "gpu": "Tesla T4",
    "gpu_count": 4,
    "gpu_devices": [
        {
            "name": "Tesla T4",
            "memory_total": 15843721216
        },
        {
            "name": "Tesla T4",
            "memory_total": 15843721216
        },
        {
            "name": "Tesla T4",
            "memory_total": 15843721216
        },
        {
            "name": "Tesla T4",
            "memory_total": 15843721216
        }
    ],
    "memory": {
        "total": 186.81336975097656
    }
}
