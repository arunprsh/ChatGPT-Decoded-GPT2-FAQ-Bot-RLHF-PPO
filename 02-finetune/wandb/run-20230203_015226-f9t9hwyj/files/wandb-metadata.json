{
    "os": "Linux-4.14.301-224.520.amzn2.x86_64-x86_64-with-glibc2.10",
    "python": "3.8.10",
    "heartbeatAt": "2023-02-03T01:52:26.774113",
    "startedAt": "2023-02-03T01:52:26.222743",
    "docker": null,
    "cuda": null,
    "args": null,
    "state": "running",
    "program": "GPT2-CUSTOM-QA-FINETUNING",
    "git": {
        "remote": "https://github.com/arunprsh/how-to-train-faq-chatbot-from-scratch.git",
        "commit": "4200794837998a6271abbbec586802a960f17d58"
    },
    "email": "arunprsh@amazon.com",
    "root": "/root/how-to-train-faq-chatbot-from-scratch",
    "host": "pytorch-1-10-gpu--ml-g4dn-12xlarge-14fecedc15dcd66d30785ee21f10",
    "username": "root",
    "executable": "/opt/conda/bin/python",
    "cpu_count": 24,
    "cpu_count_logical": 48,
    "cpu_freq": {
        "current": 2049.788125,
        "min": 0.0,
        "max": 0.0
    },
    "cpu_freq_per_core": [
        {
            "current": 1706.759,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2042.212,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2122.363,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2276.929,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2056.604,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2045.089,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2068.512,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1960.683,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2028.158,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2061.84,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2129.216,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 3002.973,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2071.587,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2057.427,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1968.998,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2057.209,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2093.189,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2165.449,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2556.754,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1866.717,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2211.265,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2009.618,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2082.299,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2073.28,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2129.931,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2124.418,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2098.686,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1707.024,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2007.124,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2022.13,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2039.286,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1883.85,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1993.828,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2019.27,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1606.318,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2056.16,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1929.691,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1986.238,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2083.007,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1454.173,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2025.88,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2190.94,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2161.285,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1963.216,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1984.746,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 1912.434,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2153.148,
            "min": 0.0,
            "max": 0.0
        },
        {
            "current": 2141.917,
            "min": 0.0,
            "max": 0.0
        }
    ],
    "disk": {
        "total": 27.0,
        "used": 1.7678375244140625
    },
    "gpu": "Tesla T4",
    "gpu_count": 4,
    "gpu_devices": [
        {
            "name": "Tesla T4",
            "memory_total": 15843721216
        },
        {
            "name": "Tesla T4",
            "memory_total": 15843721216
        },
        {
            "name": "Tesla T4",
            "memory_total": 15843721216
        },
        {
            "name": "Tesla T4",
            "memory_total": 15843721216
        }
    ],
    "memory": {
        "total": 186.81336975097656
    }
}
