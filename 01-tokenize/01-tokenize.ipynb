{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb50278-7bc0-4730-9d6a-40230c9bb056",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a713c4-d76c-48b4-9027-0b35d445ffb7",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc89c4-ae12-49a1-af03-4c9264acdb1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install --upgrade jupyter\n",
    "!pip install --upgrade ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c062292-9413-48e0-9004-cca579ae42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install transformers==4.18.0\n",
    "!pip install datasets==2.9.0\n",
    "!pip install pandas==1.4.1\n",
    "!pip install numpy==1.22.2\n",
    "!pip install torch==1.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390d1710-ea24-4e79-b136-c91636e70b09",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6414a8-8031-46b9-81c9-67f82ce25ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import set_seed\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import datasets \n",
    "import logging\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267a1f2a-de81-4d61-b23a-ce493b4cb393",
   "metadata": {},
   "source": [
    "##### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d76dc78-9c18-425b-950b-39c42d0e90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c02dbd-755a-4670-9b8f-cb83bd0d0d10",
   "metadata": {},
   "source": [
    "##### Log versions of dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04659b4b-20ad-42ca-836a-c6815dff75e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using transformers version: 4.18.0]\n",
      "[Using datasets version: 2.9.0]\n",
      "[Using torch version: 1.8.1+cu102]\n",
      "[Using pandas version: 1.4.1]\n",
      "[Using numpy version: 1.22.2]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using transformers version: {transformers.__version__}]')\n",
    "logger.info(f'[Using datasets version: {datasets.__version__}]')\n",
    "logger.info(f'[Using torch version: {torch.__version__}]')\n",
    "logger.info(f'[Using pandas version: {pd.__version__}]')\n",
    "logger.info(f'[Using numpy version: {np.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6335e8d7-3392-4f84-8007-af9df7f96807",
   "metadata": {},
   "source": [
    "#### Setup essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91152721-65c0-479c-8586-df3500e4ffcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "set_seed(123)\n",
    "\n",
    "\n",
    "N_GPUS = 1\n",
    "num_proc = int(os.cpu_count()/N_GPUS)\n",
    "num_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b3738-b0ba-474b-a777-194e9a5a2d1b",
   "metadata": {},
   "source": [
    "#### Load FAQ dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d2407e-e65a-4f9f-bd0a-70d38e16df05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-bf258d3d4adb68a9\n",
      "Found cached dataset csv (/tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('csv', \n",
    "                     data_files='./data/faq_train.csv', \n",
    "                     column_names=['question', 'answer'], \n",
    "                     delimiter=',', \n",
    "                     split='train', \n",
    "                     cache_dir='/tmp/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa975a1-db18-44b9-8bf8-f9c93bbc68b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded dataset: Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 6787\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Loaded dataset: {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d5e18-db0d-48e3-adaf-a0a94a9d43cf",
   "metadata": {},
   "source": [
    "#### Create data splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03af643f-ef6d-437b-9f63-3be0869090d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-d8a4dfe1e0f06e33.arrow and /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-4346dc9584e850e1.arrow\n",
      "Data splits: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 6108\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 679\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_validation_test = data.train_test_split(shuffle=True, seed=123, test_size=0.1)\n",
    "data_splits = DatasetDict({'train': train_validation_test['train'],  \n",
    "                           'validation': train_validation_test['test']})\n",
    "logger.info(f'Data splits: {data_splits}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106720d9-3b2c-49ac-9a34-55c1feaba736",
   "metadata": {},
   "source": [
    "#### Setup the custom GPT2 tokenizer \n",
    "\n",
    "Re-create the custom tokenizer we created in the previous medium article \"[Easily Build Your Own GPT from Scratch using AWS: A Comprehensive Guide for Domain Adaptation](https://medium.com/@shankar.arunp/easily-build-your-own-gpt-from-scratch-using-aws-51811b6355d3)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc50d07-990c-4980-b70c-c534b54e7893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Tokenizer: PreTrainedTokenizer(name_or_path='./vocab', vocab_size=50257, model_max_len=512, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|pad|>'})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('./vocab', \n",
    "                                          bos_token='<|startoftext|>',\n",
    "                                          eos_token='<|endoftext|>', \n",
    "                                          pad_token='<|pad|>')\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.model_max_length = 512\n",
    "logger.info(f'Tokenizer: {tokenizer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd1dacd-f28e-403e-91dc-6ff7684861ef",
   "metadata": {},
   "source": [
    "#### Tokenize data splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9a88a92-f751-4a97-a932-d6b9d21d4944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(samples: list):\n",
    "    questions = samples['question']\n",
    "    answers = samples['answer']\n",
    "    logger.info(f'Tokenizing QA pairs of length = {len(questions)}')\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    labels = []\n",
    "    \n",
    "    for question, answer in zip(questions, answers):\n",
    "        prompted_input = f'<|startoftext|>question: {question}<|pad|>answer: {answer}<|endoftext|>'\n",
    "        tokenized_input = tokenizer(prompted_input, \n",
    "                                    truncation=True, \n",
    "                                    max_length=512, \n",
    "                                    padding='max_length')\n",
    "        input_ids.append(tokenized_input['input_ids'])\n",
    "        attention_mask.append(tokenized_input['attention_mask'])\n",
    "        labels.append(tokenized_input['input_ids'])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6523da5e-7307-4c49-a8eb-18e43655f158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-68a378a2ec2bb870.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-4997047fdd268497.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-39ed3ccb0d8982c8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-7cb657e394cef021.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-f6cccc1bba294e26.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-984de698eae1c444.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-24afff6aeb609281.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /tmp/cache/csv/default-bf258d3d4adb68a9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-68457a2c2b016864.arrow\n",
      "Tokenized data = DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 6108\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 679\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = data_splits.map(tokenize, batched=True, num_proc=num_proc, remove_columns=['question', 'answer'])\n",
    "logger.info(f'Tokenized data = {tokenized_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9feef55-17dc-4222-b153-887028077acb",
   "metadata": {},
   "source": [
    "#### Save tokenized data splits to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21e68895-5bae-4272-869a-84705ab04b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007896900177001953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Saving the dataset (0/1 shards)",
       "rate": null,
       "total": 6108,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc64f0eee2e04484b13484d7214439dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006608724594116211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Saving the dataset (0/1 shards)",
       "rate": null,
       "total": 679,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2e398789944167850ded7778a215ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/679 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data.save_to_disk('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2293cd-f733-4ccc-8ec8-b07d40607b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
